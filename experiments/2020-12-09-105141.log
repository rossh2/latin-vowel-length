Using features: ['adjacent_coda_type', 'adjacent_syllable_type', 'antepenultimate', 'coda', 'coda_type', 'diphthong', 'postinitial', 'que', 'rhyme', 'syllable_type', 'vocab', 'vowel']
Reading data from path: ./data/Latin_words_preprocessed.txt
Total number of words (train+test): 95180
Full vocabulary size: 1362
Extracted 1660 features for 1362 syllables in vocabulary
Classifier type: RandomForestClassifier
Hyperparameters: min_samples_split=25, max_features=5, n_estimators=100
K-fold cross-validation with 5 folds, evaluate on 2 of them
              precision    recall  f1-score   support

       short       0.93      0.96      0.94     32395
        long       0.90      0.85      0.87     14666

    accuracy                           0.92     47061
   macro avg       0.91      0.90      0.91     47061
weighted avg       0.92      0.92      0.92     47061

Traceback (most recent call last):
  File "D:/Users/Hayley/Documents/Schoolwork/Harvard/Courses/115 Phonological Theory I/Squib/latin_vowel_classifier/model.py", line 164, in <module>
    train_data, test_data = data[train_index], data[test_index]
MemoryError: Unable to allocate 596. MiB for an array with shape (47061, 1660) and data type float64